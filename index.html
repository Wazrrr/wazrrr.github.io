<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Ziren Wang — Home</title>
  <meta name="description" content="Personal homepage of Ziren Wang" />
  <link rel="stylesheet" href="/assets/styles.css">
</head>
<body>
  <header>
    <h1>Ziren Wang</h1>
    
    <nav aria-label="Primary">
      <a href="/index.html" style='text-decoration:underline; opacity:1'>About</a>
      <a href="/index.html#publications">Publications</a>
      <a href="/index.html#projects">Projects</a>
      <a href="/blog/index.html" >Blog</a>
      <a href="/assets/pdf/CV.pdf" >CV</a>
      <a href="/index.html#contact">Contact</a>
    </nav>
  </header>
  <main>
  
<section id="about" class="hero" aria-label="About">
  <img src="/assets/images/profile.jpg" alt="Photo of Ziren Wang">
  <div>
    <p>I am a fourth-year undergraduate in the Yao Class at Tsinghua University, majoring in Computer Science. My academic interests center around distributed systems and ML systems.
    <br>
    I am currently working on the development of a flexible, high-performance Python framework for LLM inference with fine-grained intra-GPU resource management.</p>
  </div>
</section>

<section id="publications" aria-label="Publications">
  <h2>Publications</h2>
  <ul>
    <li>
      <em><strong>NanoFlow: Towards Optimal Large Language Model Serving Throughput</strong></em>.<br>
      Kan Zhu, Yufei Gao, Yilong Zhao, Liangyu Zhao, Gefei Zuo, Yile Gu, Dedong Xie, Tian Tang, Qinyu Xu, Zihao Ye, Keisuke Kamahori, Chien-Yu Lin, <strong>Ziren Wang</strong>, Stephanie Wang, Arvind Krishnamurthy, and Baris Kasikci<br>
      <em>19th USENIX Symposium on Operating Systems Design and Implementation (OSDI 25)</em>, Year 2025.
      <span class="small">[<a href="https://www.usenix.org/system/files/osdi25-zhu-kan.pdf" class="code-link">PDF</a>] [<a href="https://github.com/efeslab/Nanoflow" class="code-link">Code</a>]</span>
    </li>
  </ul>
</section>

    <section id="projects" aria-label="Project">
      <h2>Projects</h2>
      <ul>
        <li>
          <strong>LLM Inference</strong> [<a href="https://github.com/efeslab/Nanoflow" class="code-link">Code</a>]<br>
          Leading development of a flexible, high-performance Python framework for LLM inference with fine-grained intra-GPU resource management.  <br>
          We model SMs, memory bandwidth, and PCIe transfers as separable resources on independent streams, enabling kernel co-scheduling and overlap to maximize GPU utilization while minimizing cross-kernel interference.
        </li>
        <li>
          <strong>Network on Chip</strong> [<a href="https://github.com/Wazrrr/NoC_Project/blob/working/report.pdf" class="code-link">PDF</a>] [<a href="https://github.com/Wazrrr/NoC_Project/tree/working" class="code-link">Code</a>]<br>
          I reproduced the current SOTA algorithm for torus networks GOAL, implemented different VCs control policies and evaluated the experiment results, which shows global load balance by randomly choosing the direction to route in each dimension and therefore achieves local load balance by routing adaptively.
        </li>
        <li>
          <strong>Backend Development</strong> [<a href="https://drive.google.com/drive/folders/1tBHeWL0guWRLK0QHdO2DIooTvYpLbVak?usp=sharing" class="code-link">Slides</a>] <br>
          Our team developed an enrollment system, where we can publish announcements, and it also allows users to take exams. Additionally, there are some design tricks, such as masking, security design, and so on.
        </li>
        <li>
          <strong>Numerical Analysis</strong> [<a href="https://drive.google.com/file/d/1PrtfxQmsK72oiWPQCZ8_EBRlxLKQLdEZ/view?usp=sharing" class="code-link">PDF</a>] <br>
          We presented a new parallel decomposition algorithm that utilizes the sampling algorithm of RChol in conjunction with Multifrontal, dynamically managing the dependencies between threads and nodes. Experiments show that this algorithm can effectively improve the matrix decomposition rate when the matrix has high parallelism; however, it does not accelerate matrices that are inherently difficult to compute in parallel.
        </li>
      </ul>
    </section>


    <section id="contact" aria-label="Contact">
      <h2>Contact</h2>
      <div class="icons">
        <!-- Email -->
        <a class="icon-link" href="mailto:wang-zr22@mails.tsinghua.edu.cn" aria-label="Email" title="Email">
          <!-- Heroicons envelope (outline) -->
          <img class="icon" src="assets/icons/gmail.svg" alt="" />
        </a>
    
        <!-- GitHub (Simple Icons) -->
        <a class="icon-link" href="https://github.com/Wazrrr" aria-label="GitHub" title="GitHub">
          <img class="icon" src="assets/icons/github.svg" alt="" />
        </a>
    
        <!-- Google Scholar (Simple Icons) -->
        <a class="icon-link" href="https://scholar.google.com/citations?user=vMPVF7IAAAAJ&hl=en" aria-label="Google Scholar" title="Google Scholar">
          <img class="icon" src="assets/icons/googlescholar.svg" alt="" />
        </a>
      </div>
    </section>

  </main>
  
  <footer>
    © <span id="year"></span> Ziren Wang ·
    Updated <time id="lastmod" datetime=""></time>
  </footer>
  <script>
    // Year
    document.getElementById('year').textContent = new Date().getFullYear();
  
    // Last modified (per page)
    (function () {
      var el = document.getElementById('lastmod');
      if (!el) return;
      var last = new Date(document.lastModified);
      if (isNaN(last.getTime())) return; // safety
      // Format like "Oct 20, 2025" (change locale/options to taste)
      var formatted = new Intl.DateTimeFormat('en-US', {
        year: 'numeric', month: 'short', day: '2-digit'
      }).format(last);
      el.textContent = formatted;
      el.setAttribute('datetime', last.toISOString());
    })();
  </script>
</body>
</html>